#!/usr/bin/env python

import numpy as np
import numpy.random as npr
import matplotlib.pyplot as plt
import ssm
import psytrack as psy
import copy
from ssm.util import find_permutation
import argparse
from collections import defaultdict
import copy


def get_args():

    """This grabs arguments for setting total trials"""

    parser = argparse.ArgumentParser(description="global variables to set input file names")
    parser.add_argument("-ch", "--choices", help="choices file name", required=True, type=str)
    parser.add_argument("-ip", "--inputs", help="input file name", required=True, type=str)
    parser.add_argument("-rt", "--react_times", help="reaction times file name", required=True, type=str)
    parser.add_argument("-g", "--gname", help="graph name", required=True, type=str)
    return parser.parse_args()


def filter_no_response_cho(inputs, choices, react_times, cho=2):

    """Takes numpy arrays of inputs and choices, filters out choice 2 (no response) from choice array
    and the corresponding indexes from the inputs array to keep the shapes of both the same. Returns
    an array of filtered out choices and filtered out inputs"""

    new_choices = list()
    new_inputs = list()
    new_rts = list()
    for i in range(len(choices)):
        inds = np.squeeze(choices[i]!=cho)
        new_inputs.append(inputs[i][inds,:])
        new_choices.append(choices[i][inds])
        new_rts.append(react_times[i][inds])
    new_choices = np.array(new_choices, dtype='O')
    new_inputs = np.array(new_inputs, dtype='O')
    new_rts = np.array(new_rts, dtype='O')
    return new_inputs, new_choices, new_rts 


def fit_glm_hmm(hmm, filt_choices, filt_inpts, N_iters,TOL):

    """Takes newly initialized hmm glm model (without standard transition matrix and weights) and 
    returns a fitted glm hmm. Returns fitted glm-hmm"""

    # new_glmhmm = ssm.HMM(num_states, obs_dim, input_dim, observations="input_driven_obs", 
    #                         observation_kwargs=dict(C=num_categories), transitions="standard")

    # fit_glmhmm = new_glmhmm.fit(np.concatenate(filt_choices), inputs=np.concatenate(filt_inpts),
    #                              method="em", num_iters=N_iters, tolerance=tolerance)

    fit_glmhmm = hmm.fit(np.concatenate(filt_choices), inputs=np.concatenate(filt_inpts), method="em",
                          num_iters=N_iters, tolerance=TOL)
    #import ipdb; ipdb.set_trace()
    return fit_glmhmm

def convert_data_for_psytrack(filt_inpts, copy_cho):

    """"Takes inputs and choices generated by glmhmm. Converts iinput and choice data into appropriate
      formats for fitting psytrack. The experimental data are arranged into a list of numpy arrays each array
      represents a session. I decided for experimental data to train on all experimental data points
      and then plot weights by session. I am doing that instead of fitting the psytrack to each session data.
      Returns a dictionary with inputs and choices"""
    
    psy_choices = np.concatenate(copy_cho)
    psy_inputs = np.concatenate(filt_inpts)
    
    psy_data_dict = defaultdict(lambda: 'Not present')
    psy_data_dict['y'] = np.squeeze(psy_choices) # add choices data with removing the lowest dimension in choice data
    ins = psy_inputs
    #import ipdb; ipdb.set_trace()
    # in the original notebook they add inputs in the following way: the inputs is a 2D array at the lowest
    # level. First column is a column of inputs which are stimulus values, the second column is a shifted 
    # first column in a way: first column: (0, 1, 2, 3) second would be (0, 0, 1, 2)
    psy_data_dict['inputs'] = {'inpt1': np.column_stack((ins[0:, 0], np.roll(ins[0:, 0], 1)))} # add input data into a dictionary of inputs
    psy_data_dict['inputs']['inpt1'][0,1] = psy_data_dict['inputs']['inpt1'][0,0] # update the first first value in the second column
    return(psy_data_dict)

def fit_psytrack(psy_track_data):

    """Takes psytrack data dictionary. Fits psytrack with choice and input data. Returns:
    hyp: a dictionary of the optimized hyperparameters
    evd: the approximate log-evidence of the optimized model
    wMode: the weight trajectories of the optimized model
    hess_info a dictionary of sparse terms that relate to the Hessian of the optimal model
    """
    
    #import ipdb; ipdb.set_trace()
    # generate a dictionary of weights for the model
    weights = {'bias': 1,
               'inpt1': 1} # key is the one of the inputs key from the data dictionary, value is how
                        # many columns if that inputs matrix should be used

    K = np.sum([weights[i] for i in weights.keys()]) # the total number of weights K in the model

    # generate a dictionary of hyperparameters
    hyper= {'sigInit': 2**4.,      # Set to a single, large value for all weights. Will not be optimized further.
        'sigma': [2**-4.]*K,   # Each weight will have it's own sigma optimized, but all are initialized the same
        'sigDay': None}        # Indicates that session boundaries will be ignored in the optimization
    
    # set parameters to optimize over. If optList is empty, there will be no optimization
    optList = ['sigma'] # optimize over sigma parameter 
    # fit psytrack
    hyp, evd, wMode, hess_info = psy.hyperOpt(psy_track_data, hyper, weights, optList)
    print('finished fitting psytrack')
    return hyp, evd, wMode, hess_info

def get_glmhmm_dinmc_weights(new_glmhmm, filt_inpts, filt_choices, sess_id):

    """Takes new glmhmm, generative glmhmm, inputs, choices generated by the generative glmhmm. 
    Calculates dinamic weights for each data point in glm-hmm model by multiplying 
    stimulus and bias values by posterior probability of the state in order to compare to psytrack.
    Returns a matrix of the weights: first column are results for stimulus and second are results for bias"""

    recovered_weights = new_glmhmm.observations.params

    
    posterior_probs_new = [new_glmhmm.expected_states(data=data, input=inpt)[0]
                for data, inpt
                in zip(filt_choices, filt_inpts)]
    

    recovered_weights = np.squeeze(recovered_weights) # change dimensions of recovered weights to be (3,2)
    # perform matrix multiplication by multiplying posterior_probs_new[0] which is (11, 3) and recovered weights
    dinmc_weights_new = posterior_probs_new[sess_id]@ recovered_weights
     
    return dinmc_weights_new


##################################################################
# plot choices, and states
##################################################################

def plot_states(ax, hmm, filt_choices, filt_inputs, num_states, sess_id = None):

    """Takes fitted glm hmm and an axis object for plotting and plots states on the second subplot"""
    
    cols = ['#ff7f00', '#4daf4a', '#377eb8']
    posterior_probs_new = [hmm.expected_states(data=data, input=inpt)[0]
                for data, inpt
                in zip(filt_choices, filt_inputs)] # plot states predicted by the model not initialized with statndard weights and matrices
    #posterior_probs_true = [true_glmhmm.expected_states(data=data, input=inpt)[0]
                #for data, inpt
                #in zip(true_choice, inpts)] # plot states predicted by the model initialized with standard weights and matrices
    
    # plot true states of the model when it generated the choice data
    # x_range = np.array(range(len(true_latents[0])))
    # for i in range(len(cols)):
    #     mask = (true_latents[0] == i)
    #     y_values = np.ones(len(true_latents[0][mask]))
    #     ax.scatter(x_range[mask], y_values*1.25, c=cols[i], label=f'state {i+1}')

    
    #sess_id = 0 #session id; can choose any index between 0 and num_sess-1
    for k in range(num_states):
        ax.plot(posterior_probs_new[sess_id][:, k], label="State " + str(k + 1), lw=4,
                color=cols[k])
        #ax.plot(posterior_probs_true[sess_id][:, k], label="State " + str(k + 1), lw=2,
                #color=cols[k], linestyle='--')
    
    #plt.ylim((-0.01, 1.5))
    ax.legend(prop=dict(size=25))
    ax.set_yticks([0, 0.5, 1]) # had to remove  fontsize = 10 because mpl complained
    ax.tick_params(axis='both', which='major', labelsize=40) 
    ax.set_xlabel("trial #", fontsize = 50)
    ax.set_ylabel("p(state)", fontsize = 50)
    ax.set_title(f"States", fontsize=50)


def plot_choices(ax, filt_inpts, filt_choices, sess_id):

    """Takes fitted glm hmm and axis object for plotting and plots choices on the third subplot"""

    
    ins = filt_inpts[sess_id] # accessing 0th element in the outer list 
    ins = ins[0:, 0] # accessing entire column in the inputs 0th colunm, all rows
    cho = filt_choices[sess_id]
    cho = cho[:, 0] # accessing entire column all rows
    mask = ins != 0 # create a mask to filter out 0s
    ins = ins[mask] # using mask filter out zeroes from ins
    cho = cho[mask] # filter out corresponding indexes from choices
    bool_inpts = (ins>0).astype(int) # convert inputs into bollean array first and then bools into numbers
    correct_choices = bool_inpts == cho # compare converted number to chouses
    alpha = 0.6
    jitter = 0.05 * np.random.randn(len(cho))
    y_values_jittered = jitter+cho
    x_range = np.array(range(len(cho)))

    scatter_correct = ax.scatter(x_range[correct_choices], y_values_jittered[correct_choices], 
                                  label='correct', color='r', alpha=alpha, marker='v', s=200)
    scatter_wrong = ax.scatter(x_range[~correct_choices], y_values_jittered[~correct_choices],
                                 label='wrong', color='k',alpha=alpha, s=200)
    ax.set_yticks([0,1], ['L', 'R'])
    ax.tick_params(axis='both', which='major', labelsize=40)
    ax.legend(prop=dict(size=40))
    ax.set_xlabel("trial #", fontsize = 50)
    ax.set_ylabel("choice", fontsize = 50)
    ax.set_title(f"Choices", fontsize=50)


def plot_dinamic_weights(ax, dimc_weights, wMode, len_track):

    """Takes axes, glm-hmm dinamic weights, psytrack dinamic weights. 
    Plots psytrack and dinamic hmmglm weights on the same plot"""

    
    x_range = np.array(range(len(dimc_weights)))
    ax.plot(x_range, dimc_weights[:, 0], c='tab:blue', label=f'glmhmm_stimulus', linewidth=10)
    #ax.plot(x_range, dimc_weights[:, 1], c='tab:orange', label=f'glmhmm_bias')
    #ax.plot(x_range, wMode[0][len_track:(len_track + len(dimc_weights))], c='tab:green', label=f'psytrack_bias')
    ax.plot(x_range, wMode[1][len_track:(len_track + len(dimc_weights))], c='tab:red', label=f'psytrack_stimulus', linewidth=10)
    ax.legend(prop=dict(size=70))
    ax.tick_params(axis='both', which='major', labelsize=100)
    ax.set_xlabel("trial #", fontsize = 100)
    ax.set_ylabel("weight", fontsize = 100)
    

def plot_reaction_times(ax, react_times, sess_id):

    """Takes reaction times and axes and plots them on it's own subplot"""
    x_range = np.arange(len(react_times[sess_id]))
    ax.plot(x_range, np.squeeze(react_times[sess_id]), color = 'k')
    ax.tick_params(axis='both', which='major', labelsize=40)
    ax.set_xlabel("trial #", fontsize = 50)
    ax.set_ylabel("reaction time", fontsize = 50)
    ax.set_title(f"Reaction times", fontsize=50)


def plot_all(wMode,hmm, filt_choices, filt_inputs, num_states, filt_react_times):

    """main plotting function. Plots states, choices, psytrack and glmhmm weights on different plots"""
    
    len_track = 0 #track length of psytrack wMode array for plotting
    
    for sess_id in range(len(filt_choices)):
        fig, axes = plt.subplots(nrows=4, figsize=(100, 50), dpi=80, facecolor='w', edgecolor='k')
        
        dimc_weights = get_glmhmm_dinmc_weights(hmm, filt_inputs, filt_choices, sess_id)
                
        for i in range(4):
            if i == 0:
                plot_choices(axes[i], filt_inputs, filt_choices, sess_id) # plot mouse_choices
            if i == 1:
                plot_reaction_times(axes[i], filt_react_times, sess_id) #plot mouse reaction times
            if i == 2:
                plot_states(axes[i], hmm, filt_choices, filt_inputs, num_states, sess_id) # plot states
            if i == 3:
                plot_dinamic_weights(axes[i], (dimc_weights)*-1, wMode, len_track)
        len_track=len_track + len(dimc_weights)        
        plt.tight_layout()
        plt.savefig(f'glmhmm_psytrack_fit_{experiment}_session_{sess_id}_.png')
        plt.close(fig) # close previous figure otherwise computer runs out of memory
        
    


if __name__ == "__main__":
    args = get_args()
    choice_f: str = args.choices #holds path or file name of mouse choice data
    input_f: str = args.inputs #holds path or file name of mouse inputs data
    react_times_f = args.react_times #holds path for reaction times
    experiment: str = args.gname #holds experiment number to use as a graph header
         #load mouse inputs and choices

    inputs = np.load(input_f,allow_pickle = True) # load numpy file inputs
    choices = np.load(choice_f,allow_pickle = True) # load numpy files choices
    react_times = np.load(react_times_f, allow_pickle = True) # load numpy file reaction times
    
    
    input_dim: int = inputs[0].shape[1]  # input dimensions
    num_states = 3        # number of discrete states
    TOL: int = 10**-4 # tolerance 
    N_iters: int = 1000 # number of iterations for the fitting model

    filt_inputs, filt_choices, filt_react_times = filter_no_response_cho(inputs, choices, react_times, cho=2)
    
    obs_dim: int = filt_choices[0].shape[1]          # number of observed dimensions
    num_categories: int = len(np.unique(np.concatenate(filt_choices)))    # number of categories for output

    hmm = ssm.HMM(num_states, obs_dim, input_dim, observations="input_driven_obs", 
                   observation_kwargs=dict(C=num_categories), transitions="standard")
    fit_glmhmm = fit_glm_hmm(hmm, filt_choices, filt_inputs, N_iters,TOL)


    copy_cho = copy.deepcopy(filt_choices) #copy choice data for psytrack otherwise it will change the original 1 and 0 to 1 and 2
    psy_track_data = convert_data_for_psytrack(filt_inputs, copy_cho)
    hyp, evd, wMode, hess_info = fit_psytrack(psy_track_data)
    plot_all(wMode, hmm, filt_choices, filt_inputs, num_states, filt_react_times)

        



