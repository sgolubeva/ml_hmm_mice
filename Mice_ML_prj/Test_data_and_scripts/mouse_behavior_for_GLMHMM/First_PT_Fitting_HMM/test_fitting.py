import ssm
import numpy as np
from IPython import embed
from sklearn.model_selection import KFold
import matplotlib.pyplot as plt
import ray
import argparse


def get_args():
    parser = argparse.ArgumentParser(description="global variables to set input file names")
    parser.add_argument("-i", "--input", help="inputs file name", required=True, type=str)
    parser.add_argument("-c", "--choice", help="choices file name", required=True, type=str)
    parser.add_argument("-e", "--exp", help="experiment name to use for figure title", required=True, type=str)
    return parser.parse_args()


def train_hmm(num_states: int, inputs_train, inputs_test, choices_train, choices_test):
    """Takes number of states, trainig datasets for input and choice data returns log likelyhood"""
    print(obs_dim)
    hmm = ssm.HMM(num_states, obs_dim, input_dim, observations="input_driven_obs", 
                   observation_kwargs=dict(C=num_categories), transitions="standard")
    train_ll = hmm.fit(np.concatenate(choices_train), inputs=np.concatenate(inputs_train), method="em", num_iters=N_iters, tolerance=TOL)

    log_likely = hmm.log_likelihood(np.concatenate(choices_test), inputs=np.concatenate(inputs_test))
    return log_likely


if __name__ == "__main__":
    args = get_args()
    choice_f: str = args.choice #holds path or file name of mouse choice data
    input_f: str = args.input #holds path or file name of mouse inputs data
    experiment: str = args.exp #holds experiment number to use as a graph header

    print(input_f)
    input_f_test = r'/home/sgolubev/bioinfo/Mice_ML_prj/Test_data_and_scripts/mouse_behavior_for_GLMHMM/BW046_behavior_data/BW046_inpts.npy'
    print(input_f_test == input_f)
    input_f = input_f_test
    #load mouse inputs and choices
    inputs = np.load(input_f,allow_pickle = True)
    choices = np.load(choice_f,allow_pickle = True)

    obs_dim = choices[0].shape[1]          # number of observed dimensions
    num_categories = len(np.unique(np.concatenate(choices)))    # number of categories for output
    input_dim = inputs[0].shape[1]                                    # input dimensions
    num_states = 10

    TOL = 10**-4 # tolerance 
    N_iters = 1000 # number of iterations for the fitting model


    #split data into k number of folds and train/test the model
    nKfold=5 #split data into 5 training and 5 testing data sets
    log_likelyhood_dict = {new_list: [] for new_list in range(1, num_states+1)}
    kf = KFold(n_splits=nKfold, shuffle=True, random_state=None)
    # generate training and testing datasets for inputs and choices
    # kf.split returns indices in the given dataset
    input_train = list()
    input_test = list()
    for k in kf.split(inputs):
        for i in range(num_states):
            train_ind = k[0]
            test_ind = k[1]
            # use indices generated by kf.split to access and save actual data points
            input_train = np.take(inputs, train_ind)
            input_test = np.take(inputs, test_ind)
            choice_train = np.take(choices, train_ind)
            choice_test = np.take(choices, test_ind)
            # call fitting and testing function
            likelyhood = train_hmm(i+1, input_train, input_test, choice_train, choice_test)
            log_likelyhood_dict[i+1].append(likelyhood)


    #generate graph from the obtained likelyhood datapoints
    keys = list(log_likelyhood_dict.keys())
    values = list(log_likelyhood_dict.values())

    x = []
    y = []

    for key, val_list in zip(keys, values):
        x.extend([key] * len(val_list))
        y.extend(val_list)

    plt.scatter(x, y)
    plt.xlabel("State_n")
    plt.ylabel("Log_likelyhood")
    plt.title(f"Log_likelihood_{experiment}")
    plt.savefig(f'log_likelyhood_{experiment}.png')    
